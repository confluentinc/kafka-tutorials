transforming:
  title: "How to transform a stream of events"
  meta-description: "Learn to transform a stream of events"
  slug: "/transform-a-stream-of-events"
  problem: "you have events in a Kafka topic, and you want to change each event in some way and put it in a new topic."
  introduction: "Consider a topic with events that represent movies. Each event has a single attribute that combines its title and its release year into a string. In this tutorial, we'll write a program that creates a new topic with the title and release date turned into their own attributes."
  status:
    ksql: enabled
    kstreams: enabled
    kafka: enabled

filtering:
  title: "How to filter a stream of events"
  meta-description: "Learn to filter a stream of events"
  slug: "/filter-a-stream-of-events"
  problem: "you have events in a Kafka topic, and you want to filter some of them out so that only those you're interested in appear in another topic."
  introduction: "Consider a topic with events that represent book publications. In this tutorial, we'll write a program that creates a new topic which only contains the events for a particular author."
  status:
    ksql: enabled
    kstreams: enabled
    kafka: enabled

splitting:
  title: "How to split a stream of events into substreams"
  meta-description: "Learn to split a stream of events into substreams"
  slug: "/split-a-stream-of-events-into-substreams"
  problem: "you have events in a single Kafka topic, and you want to split it so that the events are placed into subtopics."
  introduction: "Suppose that you have a Kafka topic representing appearances of an actor or actress in a film, with each event denoting the genre. In this tutorial, we'll write a program that splits the stream into substreams based on the genre. We'll have a topic for drama films, a topic for fantasy films, and a topic for everything else."
  status:
    ksql: enabled
    kstreams: enabled
    kafka: enabled

merging:
  title: "How to merge many streams into one stream"
  meta-description: "Learn to merge many streams into one stream"
  slug: "/merge-many-streams-into-one-stream"
  problem: "you have many Kafka topics with events in them, and you want to merge them all into a single topic."
  introduction: "Suppose that you have a set of Kafka topics representing songs being played of a particular genre. You might have a topic for rock songs, another for classical songs, and so forth. In this tutorial, we'll write a program that merges all of the song play events into a single topic."
  status:
    ksql: enabled
    kstreams: enabled
    kafka: enabled

joining-stream-table:
  title: "How to join a stream and a table together"
  meta-description: "Learn to join a stream and a table together"
  slug: "/join-a-stream-to-a-table"
  problem: "you have events in a Kafka topic and a table of reference data. You want to join each event in the stream to a piece of data in the table based on a common key."
  introduction: "Suppose you have a set of movies that have been released and a stream of ratings from movie-goers about how entertaining they are. In this tutorial, we'll write a program that joins each rating with content about the movie."
  status:
    ksql: enabled
    kstreams: enabled

joining-table-table:
  title: "How to join a table and a table together"
  meta-description: "Learn to join a table and a table together"
  slug: "/join-a-table-to-a-table"
  problem: "you have two Kafka topics representing current state for keys — in other words, reference data. You want to join between two of these tables on a common key."
  introduction: "Suppose you have a set of data about movies and want to add further details such as who the lead actor was. In this tutorial, we'll write a program that joins each movie to another set of data holding information about who the lead actor was for movies."
  status:
    ksql: enabled
    kstreams: enabled

joining-stream-stream:
  title: "How to join a stream and a stream together"
  meta-description: "Learn to join a stream and a stream together"
  slug: "/join-a-stream-to-a-stream"
  problem: "you have two Kafka topics whose events share a common identifying attribute and correlate during some period of time. You want to join the topics together and create a new one based on that attribute, where the new events are enriched from the original topics."
  introduction: "Suppose you have two streams containing events for orders and shipments. In this tutorial, we'll write a program that joins these two streams to create a new, enriched one. The new stream will tell us which orders have been successfully shipped, how long it took for them to ship, and which warehouse they shipped from."
  status:
    ksql: enabled
    kstreams: enabled

fk-joins:
  title: "How to join a table and a table with a foreign key"
  meta-description: "Learn how to join two tables with different primary keys"
  slug: "/foreign-key-joins"
  problem: "you need to join two tables, but they have different primary keys"
  introduction: "Suppose you are running an internet streaming music service where you offer albums or individual music tracks for sale.  You'd like to track trends in listener preference by joining the track purchases against the table of albums.  The issue is that the track purchase key doesn't align with the primary key for the album table.  However, since the value of the track purchase contains the id of the album, you can extract the album id from the track purchase and complete a foreign key join against the album table."
  status:
    kstreams: enabled

rekeying:
  title: "How to rekey a stream with a value"
  meta-description: "Learn to rekey a stream with a value"
  slug: "/rekey-a-stream"
  problem: "you have a Kafka topic and you want to change the key of the messages. It may be there is no key and you want to set one, or there is a key but you want to change it to a field from the record value."
  introduction: "Suppose you have an unkeyed stream of movie ratings from movie-goers. Because the stream is not keyed, ratings for the same movie aren't guaranteed to be placed into the same partition. In this tutorial, we'll write a program that creates a new topic keyed by the movie's name. When the key is consistent, it becomes possible to process these ratings at scale and in parallel."
  status:
    ksql: enabled
    kstreams: enabled

rekeying-function:
  title: "How to rekey a stream with a function"
  meta-description: "Learn to rekey a stream with a function"
  slug: "/rekey-with-function"
  problem: "you have a Kafka topic and you want to change the key of the messages. The new key is a variation of data you currently have in the messages. A small fragment of code could convert the data you have to the new key."
  introduction: "Consider a stream of customer information events keyed by id. Each event contains a few attributes, including the customer's phone number. In this tutorial, we'll write a program that rekeys the topic by the area code of the phone number. Customers of the same area code will be placed into the same partition in the new topic."
  status:
    ksql: enabled
    kstreams: enabled

tumbling-windows:
  title: "How to create tumbling windows"
  meta-description: "Learn to create tumbling windows"
  slug: "/create-tumbling-windows"
  problem: "you have time-series events in a Kafka topic, and you want to group them into fixed-size, non-overlapping, contiguous time intervals."
  introduction: "Suppose you have a topic with events that represent ratings of movies. In this tutorial, we'll write a program that maintains tumbling windows counting the total number of ratings that each movie has received."
  status:
    ksql: enabled
    kstreams: enabled

hopping-windows:
  title: "How to create hopping windows"
  meta-description: "Learn to create hopping windows"
  slug: "/create-hopping-windows"
  problem: "you have time-series events in a Kafka topic, and you want to group them into fixed-size, possibly-overlapping, contiguous time intervals to identify an specific scenario."
  introduction: "You want to build an alerting system that automatically detects if the temperature of a room consistently drops. In this tutorial, we'll write a program that monitors a stream of temperature readings and detects when the temperature consistently drops below 45 °F for a period of 10 minutes."
  status:
    ksql: enabled

session-windows:
  title: "Create session windows"
  slug: "/create-session-windows"
  problem: "you have time-series events in a Kafka topic, and you want to group them into variable-size, non-overlapping time intervals based on a configurable inactivity period."
  introduction: "Given a topic of click events on a website, there are various ways that we can process it. As well as simply counting the number of clicks in a regular time frame (using hopping or tumbling windows), we can also perform sessionization on the data. Here the length of the time window is based on the concept of a session, which is defined based on a period of inactivity. A given user might visit a website multiple times a day, but in distinct visits. Using session windows, we can analyze the number of clicks and duration per visit."
  status:
    ksql: enabled

aggregating-count:
  title: "How to count a stream of events"
  meta-description: "Learn to count a stream of events"
  slug: "/create-stateful-aggregation-count"
  problem: "you have data in a Kafka topic and want to count the number of events based on some criteria."
  introduction: "Suppose you have a topic with events that represent ticket sales for movies. In this tutorial, we'll write a program that calculates the total number of tickets sold per movie."
  status:
    ksql: enabled
    kstreams: enabled
aggregating-minmax:
  title: "How to find the min/max in a stream of events"
  meta-description: "Learn to find the min/max in a stream of events"
  slug: "/create-stateful-aggregation-minmax"
  problem: "you have data in a Kafka topic and want to get the minimum or maximum value of a field."
  introduction: "Suppose you have a topic with events that represent ticket sales of movies. In this tutorial, we'll write a program that calculates the maximum and minimum revenue of movies by year."
  status:
     ksql: enabled
     kstreams: enabled

aggregating-sum:
   title: "How to sum a stream of events"
   meta-description: "Learn to sum a stream of events"
   slug: "/create-stateful-aggregation-sum"
   problem: "you have data in a Kafka topic and want to calculate the sum of one or more fields."
   introduction: "Suppose you have a topic with events that represent ticket sales for movies. Each event contains the movie that the ticket was purchased for as well as its price. In this tutorial, we'll write a program that calculates the sum of all ticket sales per movie."
   status:
     ksql: enabled
     kstreams: enabled

serialization:
  title: "How to convert a stream's serialization format"
  meta-description: "Learn to convert a stream's serialization format"
  slug: "/changing-serialization-format"
  problem: "you have a Kafka topic with the data serialized in a particular format, and you want to change the format to something else."
  introduction: "Consider a topic with events that represent movie releases. The events in the topic are formatted with JSON. In this tutorial, we'll write a program that creates a new topic with the same events, but formatted with Avro."
  status:
    ksql: enabled
    kstreams: enabled

connect-add-key-to-source:
  title: "Add key to data ingested through Kafka Connect"
  slug: "/connect-add-key-to-source"
  problem: "You have data in a source system (such as a database) that you want to stream into Kafka using Kafka Connect. You want to add a key to the data as part of the ingest."
  introduction: "Kafka Connect is the integration API for Apache Kafka. It enables you to stream data from source systems (such databases, message queues, SaaS platforms, and flat files) into Kafka, and from Kafka to target systems. When you stream data into Kafka you often need to set the key correctly for partitioning and application logic reasons. In this example there is data about cities in a database, and we want to key the resulting Kafka message by the city_id field. There are different ways to set the key correctly and these tutorials will show you how. It will also cover how to declare the schema and use Kafka Streams to process the data using SpecificAvro. "
  status:
    ksql: enabled
    kafka: enabled
    kstreams: enabled

finding-distinct:
  title: "How to find distinct values in a stream of events"
  slug: "/finding-distinct-events"
  problem: "you have events in a Kafka topic, and you want to filter out duplicate events based on a field in the event, producing a new stream of unique events per time window"
  introduction: "Consider a topic with events that represent clicks on a website.  Each event contains an IP address, a URL, and a timestamp.  In this tutorial, we'll write a program that filters click events by the IP address within a window of time."
  status:
    ksql: enabled
    kstreams: enabled
    kafka: disabled

window-final-result:
  title: "Emit a final result from a time window"
  slug: "/window-final-result"
  problem: "you have a Kafka topic, and you want to count the number of messages per key over a time window, getting a final result that takes late arrivals into account."
  introduction: "Consider a topic with events that represent sensor warnings (pressure on robotic arms). One warning per time slot is fine, but you don't want to have too much warnings at the same time. In this tutorial, we'll write a program that counts the messages of a same sensor and sends a result at the end of the window."
  status:
    kstreams: enabled

udf:
  title: "How to build a User-Defined Function (UDF) to transform events"
  slug: "/udf"
  problem: "you have events in a Kafka topic, and you want to transform the values using a stateless scalar function not already provided by KSQL"
  introduction: "Consider a topic of stock price events that you want to calculate the <a href=\"https://en.wikipedia.org/wiki/Volume-weighted_average_price\">volume-weighted average price</a> (VWAP) for each event, publishing the result to a new topic.  There is no built-in function for VWAP, so we'll write a custom <a href=\"https://docs.confluent.io/current/ksql/docs/developer-guide/udf.html\">KSQL UDF</a> that performs the calculation."
  status:
    ksql: enabled
    kstreams: disabled
    kafka: disabled

deserialization-errors:
  title: "How to handle deserialization errors"
  meta-description: "How to handle deserialization errors"
  slug: "/handling-deserialization-errors"
  problem: "you have created a stream/table that contains a schema associated, and you want to understand why some events are not being written correctly."
  introduction: "During the development of event streaming applications, it is very common to have situations where some streams or tables are not receiving some events that has been sent to it. Often this happens because there was an deserialization error due to the event not being in the right format, but that is not so trivial to figure out. In this tutorial, we'll write a program that monitors a stream of sensors. Any deserialization error that happens in this stream will be made available in another stream that can be queried to check errors."
  status:
    ksql: enabled
    
flatten-nested-data:
  title: "How to flatten deeply nested events"
  meta-description: "How to flatten deeply nested events"
  slug: "/flatten-nested-data"
  problem: "you have events with nested data in a Kafka topic, and you want to transform each event into a flattened dataset that is simpler to handle."
  introduction: "Consider a topic containing product orders. Each order contains data about the customer and the product, specified as nested data. In this tutorial, we'll write a program that transforms each order into a new version of it that contains all the data as flat fields."
  status:
    ksql: enabled
    kstreams: disabled
    kafka: disabled

aggregating-average:
  title: "Compute an average aggregation"
  meta-description: "Compute an average aggregation"
  slug: "/aggregating-average"
  problem: "Kafka Streams natively supports \"incremental\" aggregation functions, in which the aggregation result is updated based on the values captured by each window. Incremental functions include count, sum, min, and max. An average aggregation cannot be computed incrementally. However, as this tutorial shows, it can be implemented by composing incremental functions, namely count and sum."
  introduction: "Consider a topic with events that represent ratings of movies. In this tutorial, we'll write a program that calculates and maintains a running average rating for each movie."
  status:
    ksql: disabled
    kstreams: enabled
    kafka: disabled

dynamic-output-topic:
  title: "How to dynamically choose the output topic"
  meta-description: "How to dynamically choose the output topic"
  slug: "/dynamic-output-topic"
  problem: "you need to determine which topic to send records to dynamically"
  introduction: "Consider a situation where, depending on data in your records, you need to direct output to different topic.  In this tutorial, you'll learn how to instruct Kafka Streams to choose the output topic at runtime."
  status:
    ksql: disabled
    kstreams: enabled
    kafka: disabled

naming-changelog-repartition-topics:
  title: "How to name stateful operations in Kafka Streams"
  meta-description: "How to name stateful operations in Kafka Streams"
  slug: "/naming-stateful-operations"
  problem: "you have an existing Kafka Streams application and you want to make changes to the topology, but you'd like the new topology to remain compatible with the existing one"
  introduction: "You want to add or remove some operations in your Kafka Streams application.  In this tutorial we'll name the changelog and repartition topics so that the topology updates don't break compatibility."
  status:
    ksql: disabled
    kstreams: enabled
    kafka: disabled

cogrouping-streams:
  title: "How to combine stream aggregates together in a single larger object"
  meta-description: "How to combine stream aggregates together in a single larger object"
  slug: "/cogrouping-streams"
  problem: "you have multiple streams, each with an aggregate value like `count`,  that you want to combine into a single result"
  introduction: "You want to compute the count of user login events per application in your system, grouping the individual result from each source stream into one aggregated object.  In this tutorial we'll cover how to use the Kafka Streams Cogrouping functionality to accomplish this task with clear, performant code"
  status:
    ksql: disabled
    kstreams: enabled
    kafka: disabled

console-consumer-produer-basic:
  title: "Console Producer and Consume Basics"
  meta-description: "Produce and consume your first message with Kafka"
  slug: "/kafka-console-consumer-producer-basics"
  problem: "you are brand new to Kafka and you want to experiment by producing and consuming a message quickly"
  introduction: "So you are excited to get started with Kafka and youd like to produce and consume some basic messages and you want to do so quickly.  In this tutorial we'll show you how to produce and consume messages from the command line with no code! Note this tutorial doesn't cover using (de)serializers. Using (de)serializers with the console consumer and producer are covered in separate tutorials"
  status:
    ksql: disabled
    kstreams: disabled
    kafka: enabled
    
