Then create the following file at `src/main/java/io/confluent/developer/AggregatingMinMax.java`. 

+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/aggregating-minmax/kstreams/code/src/main/java/io/confluent/developer/AggregatingMinMax.java %}</code></pre>
+++++

Let's take a close look at the `buildTopology()` function, which uses the Kafka Streams DSL.

Using the `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]` parameter, which is the helper object that lets us build our topology, we can apply the following sequence of stages:

1. Call the `stream()` function which creates a `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KStream.html[KStream]<String, MovieTicketSales>` object based on the stream of records from the `inputTopic` Kafka topic.

2. Our use case requires we calculate minimum and maximum movie revenue _by year_.  The `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KStream.html#groupBy-org.apache.kafka.streams.kstream.KeyValueMapper-[groupBy]` function creates a `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KGroupedStream.html[KGroupedStream]` object.  `KGroupedStream` represents a 'grouped record stream' which allows us to apply aggregations over the records, grouped by a the key.  Here, we are specifying the movie's year of release as the record value on which to group.  Because you are changing the key, Kafka Streams automatically re-partitions the data.

3. Next we apply the `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KGroupedStream.html#aggregate-org.apache.kafka.streams.kstream.Initializer-org.apache.kafka.streams.kstream.Aggregator-org.apache.kafka.streams.kstream.Materialized-[aggregate]` function which allows us to combine record values over time as well as change the type of the result records from the type of the input records.  In our example we are aggregating `MovieTicketSales` records into the `YearlyMovieFigures` type by calculating a minimum and maximum value, grouped by `release_year`.  The first parameter given to `aggregate` is an `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/Initializer.html[Initializer]` which is used for creating the initial value used in the first aggregation invocation.  In our case, we are providing an instance of `YearlyMovieFigures` initialized with values that will make calculating minimum and maximums easy.  The second parameter to the function is the aggregation logic.  Here we calculate new minimum and maximums by comparing the incoming new `MovieTicketSales` record with the most recent aggregate value and we return a `YearlyMovieFigures` instance.  This `YearlyMovieFigures` instance is the new aggregated value which will propogate downstream as well as be the value returned to us in the next invocation of `aggregate`.  The final parameter to `aggregate` is a `Materialized` object which contains the `https://kafka.apache.org/{{ page.ak_javadoc_version }}/javadoc/org/apache/kafka/common/serialization/Serdes.html[Serdes]` required for (de)serializing records for the state store backing the aggregation. 

4. Finally the chain of functions, `toStream().to(...)`, produces the aggregated results to the specified output topic.
