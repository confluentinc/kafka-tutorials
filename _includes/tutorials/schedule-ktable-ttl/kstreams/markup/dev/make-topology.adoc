Next we setup simple KStream-KTable join to have a KTable that we will attach a TTLEmitter to.

[source, java]
.Initializing a simple KStream-KTable join in the Kafka Streams application
----
// Read the input data.
    final KStream<String, String> stream =
        builder.stream(inputTopicForStream, Consumed.with(Serdes.String(), Serdes.String()));
    final KTable<String, String> table = builder.table(inputTopicForTable,
        Consumed.with(Serdes.String(), Serdes.String()));


    // Perform the custom join operation.
    final KStream<String, String> joined = stream.leftJoin(table, (left, right) -> {
      System.out.println("JOINING left="+left+" right="+right);
      if (right != null)
        return left+" "+right; // this is, of course, a completely fake join logic
      return left;
    });
    // Write the join results back to Kafka.
    joined.to(outputTopic,
        Produced.with(Serdes.String(), Serdes.String()));
----

Next we attach a transformer to the original table in order to do the work of emitting tombstones as appropriate:

[source, java]
.Attaching a transformer to the KTable and writing back to the KTable's input topic
----
    // TTL part of the topology
    // This could be in a separate application
    // Setting tombstones for records seen past a TTL of MAX_AGE
    final Duration MAX_AGE = Duration.ofMinutes(Integer.parseInt(envProp.getProperty("table.topic.ttl.minutes"))); <1>
    final Duration SCAN_FREQUENCY = Duration.ofSeconds(Integer.parseInt(envProp.getProperty("table.topic.ttl.scan.seconds")));
    final String STATE_STORE_NAME = envProp.getProperty("table.topic.ttl.store.name");



    // adding a custom state store for the TTL transformer which has a key of type string, and a
    // value of type long
    // which represents the timestamp
    final StoreBuilder<KeyValueStore<String, Long>> storeBuilder = Stores.keyValueStoreBuilder( <2>
        Stores.persistentKeyValueStore(STATE_STORE_NAME),
        Serdes.String(),
        Serdes.Long()
    );


    builder.addStateStore(storeBuilder); <3>

    // tap the table topic in order to insert a tombstone after MAX_AGE based on event time
    //builder.stream(inputTopicForTable, Consumed.with(Serdes.String(), Serdes.String()))
    table.toStream()  //we just have to do this part for doing in the same topology but in another app, you can do as above 
        .transform(() -> new TTLEmitter<String, String, KeyValue<String, String>>(MAX_AGE, <3>
            SCAN_FREQUENCY, STATE_STORE_NAME), STATE_STORE_NAME)
        .to(inputTopicForTable, Produced.with(Serdes.String(), Serdes.String())); // write the
                                                                                // tombstones back
                                                                                // out to the input
                                                                                // topic
----
<1> Loading some variables from the properties file
<2> Initialization of the purge state store builder
<3> Tell the topology builder about state store builder
<4> Turn the table into a stream and call transform on it with the TTL Emitter


Create the TTLEmitter class by copying the following file to src/main/java/io/confluent/developer/TTLEmitter.java:

+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/schedule-ktable-ttl/kstreams/code/src/main/java/io/confluent/developer/TTLEmitter.java %}</code></pre>
+++++


Create the KafkaStreamsKTableTTLExample class by copying the following file to src/main/java/io/confluent/developer/KafkaStreamsKTableTTLExample.java:

+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/schedule-ktable-ttl/kstreams/code/src/main/java/io/confluent/developer/KafkaStreamsKTableTTLExample.java %}</code></pre>
+++++


