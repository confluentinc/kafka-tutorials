Now that the Kafka Streams application is running, run a command line consumer using the `kafka-console-consumer` CLI to view the events.

In a new terminal window, run the following console consumer to view the events being generated by the data generator and produced to the `random-strings` topic from the `Randomizer` class in your Kafka Streams application. These are the events that have been streamed into the topology (`.stream(inputTopic, Consumed.with(stringSerde, stringSerde)`).

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/creating-first-apache-kafka-streams-application/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>
+++++

You should see output that looks like this (notice the mixed case of the string):

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/creating-first-apache-kafka-streams-application/kstreams/code/tutorial-steps/dev/expected-consume-output.txt %}</code></pre>
+++++

Next, look at the transformed events in the `tall-random-strings` topic. These are the events that have been transformed (`.mapValues`) and written to the output topic `.to(outputTopic, Produced.with(stringSerde, stringSerde))`.

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/creating-first-apache-kafka-streams-application/kstreams/code/tutorial-steps/dev/console-consumer-transformed.sh %}</code></pre>
+++++

You should see output events that are entirely upper case:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/creating-first-apache-kafka-streams-application/kstreams/code/tutorial-steps/dev/expected-consume-transformed-output.txt %}</code></pre>
+++++

Once you are done with observing the behavior of the application, stop the consumers and the Kafka Streams application with `Ctrl-C` in the appropriate terminal windows.

Finally, shutdown Confluent Platform by invoking `docker compose down -v`.
