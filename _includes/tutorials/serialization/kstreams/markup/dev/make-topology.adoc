Then create the following file at `src/main/java/io/confluent/developer/serialization/SerializationTutorial.java`.
    
+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/serialization/kstreams/code/src/main/java/io/confluent/developer/serialization/SerializationTutorial.java %}</code></pre>
+++++

Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.
The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology.
First, we call the `stream()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KStream.html[KStream]<Long, Movie>` object.


Even though we specified `StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG` and `StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG` in Streams Configuration, Kafka Streams DSL allows us to specify serializer / deserializer during stream creation.

[source,java]
----
builder.stream(inputJsonTopicName, Consumed.with(Long(), new MovieJsonSerde())); //<1>
avroMoviesStream.to(outAvroTopicName, Produced.with(Long(), movieSpecificAvroSerde)); //<2> 
----
<1> Using `Consumed.with` method we specify deserializer to use during creating of stream.
<2> Similarly, during production to the topic, we can specify what serializer to use and in what format to produce data to the topic. 