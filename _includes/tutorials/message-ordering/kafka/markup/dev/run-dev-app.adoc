Now that you have an uberjar for the KafkaProducerApplication, you can launch it locally.
+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/message-ordering/kafka/code/tutorial-steps/dev/run-dev-app.sh %}</code></pre>
+++++

After you run the previous command, the application will process the file and you should some logs like this on the console:

[source, text]
----
[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=myApp] Instantiated an idempotent producer. <1>
....
[kafka-producer-network-thread | myApp] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=myApp] ProducerId set to 0 with epoch 0 <2>
----

<1> The producer is configured for idempotency

<2> This app has been assigned `ProducerId=0` (If you were to run the app again, then it would increase to `ProducerId=1`)

And then you should see the output from the Producer application, which displays confirmation at which offset each record was written to via a `Callback` lambda expression:

[source, text]
----
Offsets and timestamps committed in batch from input.txt
key/value a/1   written to topic[partition] myTopic[0] at offset 0
key/value b/2   written to topic[partition] myTopic[0] at offset 1
key/value c/3   written to topic[partition] myTopic[0] at offset 2
key/value a/5   written to topic[partition] myTopic[0] at offset 3
key/value b/6   written to topic[partition] myTopic[0] at offset 4
key/value c/7   written to topic[partition] myTopic[0] at offset 5
key/value a/9   written to topic[partition] myTopic[0] at offset 6
key/value b/10  written to topic[partition] myTopic[0] at offset 7
key/value c/11  written to topic[partition] myTopic[0] at offset 8
key/value d/4   written to topic[partition] myTopic[1] at offset 0
key/value d/8   written to topic[partition] myTopic[1] at offset 1
key/value d/12  written to topic[partition] myTopic[1] at offset 2
----
