Now that you have an uberjar for the KafkaProducerApplication, you can launch it locally.
+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/message-ordering/kafka/code/tutorial-steps/dev/run-dev-app.sh %}</code></pre>
+++++

After you run the previous command, the application will process the file and you should some logs like this on the console:

[source, text]
----
[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=myApp] Instantiated an idempotent producer. <1>
....
[kafka-producer-network-thread | myApp] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=myApp] ProducerId set to 0 with epoch 0 <2>
----

<1> The producer is configured for idempotency

<2> This app has been assigned `ProducerId=0` (If you were to run the app again, then it would increase to `ProducerId=1`)

And then you should see the output from the Producer application, which displays confirmation at which offset each record was written to:

[source, text]
----
Offsets and timestamps committed in batch from input.txt
Record written to topic myTopic partition 0 offset 0
Record written to topic myTopic partition 0 offset 1
Record written to topic myTopic partition 0 offset 2
Record written to topic myTopic partition 0 offset 3
Record written to topic myTopic partition 0 offset 4
Record written to topic myTopic partition 0 offset 5
Record written to topic myTopic partition 0 offset 6
Record written to topic myTopic partition 0 offset 7
Record written to topic myTopic partition 0 offset 8
Record written to topic myTopic partition 1 offset 0
Record written to topic myTopic partition 1 offset 1
Record written to topic myTopic partition 1 offset 2
----
