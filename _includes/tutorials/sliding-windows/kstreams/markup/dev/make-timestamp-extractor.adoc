////
In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.
The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.
////

Before you create the Kafka Streams application you'll need to create an instance of a https://kafka.apache.org/27/javadoc/org/apache/kafka/streams/processor/TimestampExtractor.html[TimestampExtractor].  In Kafka Streams, timestamps drive the progress of records in the application.  https://docs.confluent.io/platform/current/streams/developer-guide/config-streams.html#default-timestamp-extractor[By default], Kafka Streams uses the timestamps contained in the https://kafka.apache.org/27/javadoc/org/apache/kafka/clients/consumer/ConsumerRecord.html[ConsumerRecord].  But you can configure your application to use timestamps embedded in the record payload itself.  You do this by creating an class implementing the `TimestampExtractor` interface and provide the class name when configuring your Kafka Streams application like so:

[source, java]
----
 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, TemperatureReadingTimestampExtractor.class.getName());
----


We're going to create a custom `TimestampExtractor` so the Kafka Streams application uses the timestamps embedded in our generated IoT sensor readings.

Create the following file at `src/main/java/io/confluent/developer/TemperatureReadingTimestampExtractor.java`

+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/sliding-windows/kstreams/code/src/main/java/io/confluent/developer/TemperatureReadingTimestampExtractor.java %}</code></pre>
+++++

You'll take care of the configuration when you create the Kafka Streams topology in the next step.
