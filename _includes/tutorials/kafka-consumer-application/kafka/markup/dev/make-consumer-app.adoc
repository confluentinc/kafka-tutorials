////
In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.
The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.
////

To complete this tutorial, you'll build a main application class and a helper class


First, you'll create the main application,`KafkaConsumerApplication`, which is the focal point of this tutorial; consuming records from a Kafka topic.


Let's go over some of the key parts of the `KafkaConsumerApplication` starting with the constructor:

[source, java]
.KafkaConsumerApplication constructor
----
public KafkaConsumerApplication(final Consumer<String, String> consumer,
                                final ConsumerRecordsHandler<String, String> recordsHandler) { // <1>
    this.consumer = consumer;
    this.recordsHandler = recordsHandler;
}
----

<1> Here you're suppling instances of the `Consumer` and `ConsumerRecordsHandler` via constructor parameters.

By using interfaces vs. concreate implentations you can more easily test the `KafkaConsumerApplication` class by swapping in a `MockConsumer` for the test.  We'll cover testing in an upcoming section.  Also, interfaces make it simple to change `ConsumerRecord` handling at run-time.

In this tutorial you'll inject the dependencies in the `KafkaConsumerApplication.main()` method, but in practice you may want to use a dependency injection framework library, such as the  https://spring.io/projects/spring-framework[Spring Framework].


Next, let's review the `KafkaConsumerApplication.runConsumer()` method, which provides the core functionality of this tutorial.

[source, java]
.KafkaConsumerApplication.process
----
  public void runConsume(final Properties consumerProps) {
    try {
      consumer.subscribe(Collections.singletonList(consumerProps.getProperty("input.topic.name"))); // <1>
      while (keepConsuming) { // <2>
        final ConsumerRecords<String, String> consumerRecords = consumer.poll(Duration.ofSeconds(1));  // <3>
        recordsHandler.process(consumerRecords); // <4>
      }
    } finally {
      consumer.close(); // <5>
    }
  }
----

<1> Subscribing to the Kafka topic.
<2> Using an instance variable `keepConsuming` to run the Kafka consumer indefinitely.  The `KafkaConsumerApplication.shutdown()` method sets `keepConsuming` to `false`.
<3> Polling for new records, waiting at most one second for new records.  The `Consumer.poll()` method may return zero results.  The consumer is expected to call `poll()` again within five minutes, from the `max.poll.interval.ms` config described in step three, "Configure the project".
<4> Handing off the polled `ConsumerRecords` to the `ConsumerRecordsHandler` interface.
<5> Closing the consumer is essential to prevent resource leaking, hence the `finally` block.




Now go ahead and create the `src/main/java/io/confluent/developer/KafkaConsumerApplication.java` file:

+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/kafka-consumer-application/kafka/code/src/main/java/io/confluent/developer/KafkaConsumerApplication.java %}</code></pre>
+++++
