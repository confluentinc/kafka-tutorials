version: '2'
services:
  broker:
    image: confluentinc/cp-kafka:7.4.1
    hostname: broker
    container_name: broker
    ports:
    - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
      KAFKA_LISTENERS: PLAINTEXT://broker:9092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
    - broker
    ports:
    - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:9092
  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:7.3.0
    hostname: ksqldb
    container_name: ksqldb
    depends_on:
    - broker
    ports:
    - 8088:8088
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: broker:9092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_HIDDEN_TOPICS: ^_.*
      KSQL_KSQL_CONNECT_WORKER_CONFIG: /connect/connect.properties
      KSQL_CONNECT_BOOTSTRAP_SERVERS: broker:9092
      KSQL_CONNECT_REST_ADVERTISED_HOST_NAME: ksqldb
      KSQL_CONNECT_GROUP_ID: ksqldb-kafka-connect-group-01
      KSQL_CONNECT_CONFIG_STORAGE_TOPIC: _ksqldb-kafka-connect-group-01-configs
      KSQL_CONNECT_OFFSET_STORAGE_TOPIC: _ksqldb-kafka-connect-group-01-offsets
      KSQL_CONNECT_STATUS_STORAGE_TOPIC: _ksqldb-kafka-connect-group-01-status
      KSQL_CONNECT_KEY_CONVERTER: org.apache.kafka.connect.converters.LongConverter
      KSQL_CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.converters.DoubleConverter
      KSQL_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '1'
      KSQL_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '1'
      KSQL_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '1'
      KSQL_CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: '[%d] %p %X{connector.context}%m
        (%c:%L)%n'
      KSQL_CONNECT_PLUGIN_PATH: /usr/share/java,/home/appuser/confluent-hub-components/,/data/connect-jars
    volumes:
    - ./primitives.json:/schema/primitives.json
    command:
    - bash
    - -c
    - "echo \"Installing connector plugins\"\nmkdir -p /home/appuser/confluent-hub-components/\nconfluent-hub
      install --no-prompt --component-dir /home/appuser/confluent-hub-components/
      --worker-configs /dev/null confluentinc/kafka-connect-datagen:0.6.0\n#\necho
      \"Launching ksqlDB\"\n/etc/confluent/docker/run &\n\n echo \"Waiting for Kafka
      Connect to start listening on localhost ⏳\"\nwhile : ; do\n  curl_status=$$(curl
      -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)\n  echo -e
      $$(date) \" Kafka Connect listener HTTP state: \" $$curl_status \" (waiting
      for 200)\"\n  if [ $$curl_status -eq 200 ] ; then\n    break\n  fi\n  sleep
      5 \ndone\n\necho -e \"\\n--\\n+> Creating Data Generator source\"\ncurl -X PUT
      http://localhost:8083/connectors/example/config \\\n -i -H \"Content-Type: application/json\"
      -d'{\n    \"connector.class\": \"io.confluent.kafka.connect.datagen.DatagenConnector\",\n
      \   \"schema.filename\": \"/schema/primitives.json\",\n    \"schema.keyfield\":
      \"key_field\",\n    \"kafka.topic\" : \"example\",\n    \"iterations\" : 10,\n
      \   \"transforms\": \"extractValue\",\n    \"transforms.extractValue.type\":
      \"org.apache.kafka.connect.transforms.ExtractField$$Value\",\n    \"transforms.extractValue.field\":
      \"value_field\",\n    \"key.converter\": \"org.apache.kafka.connect.converters.LongConverter\",\n
      \   \"key.converter.schemas.enable\" : \"false\",\n    \"value.converter\":
      \"org.apache.kafka.connect.converters.DoubleConverter\",\n    \"value.converter.schemas.enable\"
      : \"false\",\n    \"tasks.max\": 1\n}'\n\nsleep infinity\n"
