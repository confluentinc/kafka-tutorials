With our test data in place, let's try a query to compute the min and max. A `SELECT` statement in Flink SQL is called a _continuous query_ because it will continue to run and produce results dynamically. This query is _transient_, meaning that after we stop it, it is gone and will not keep processing the input stream. Further, the results aren't persisted anywhere. We'll create a _persistent_ query, the contrast to a transient push query, a few steps from now.

If youâ€™re familiar with SQL, the text of the query itself is fairly self-explanatory. We are calculating the total number of records in each group, grouped by movie title. Note that `COUNT(ticket_total_value)` is still just counting the number of rows in the group, and is not doing any calculation based on ticket value itself. This query will keep running, continuing to return results until you hit CTRL-C.

+++++
<pre class="snippet"><code class="sql">{% include_raw tutorials/aggregating-count/flinksql/code/tutorial-steps/dev/transient-query.sql %}</code></pre>
+++++

This should yield the following output:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/aggregating-count/flinksql/code/tutorial-steps/dev/expected-transient-query.log %}</code></pre>
+++++

Enter `Q` to return to the Flink SQL prompt.

Note that these results were materialized in memory and printed in a human readable table representation because the default `sql-client.execution.result-mode` configuration value is `table`. You can view non-materialized streaming results as a changelog by running `SET 'sql-client.execution.result-mode' = 'changelog';`
and rerunning the same query. The results will look like this:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/aggregating-count/flinksql/code/tutorial-steps/dev/expected-transient-query-changelog.log %}</code></pre>
+++++

Or, as a third option, you can see streaming results non-materialized and inline in the SQL client by running ``SET 'sql-client.execution.result-mode' = 'tableau';`` and rerunning the query once more. In this case, the results will look very similar to `changelog` mode results. This is because tables sourced by the Kafka connector are _unbounded_ and can thus only be queried in `streaming` mode. For further reading on these Flink SQL concepts, consult the documentation on  https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/dev/table/sqlclient/#sql-client-result-modes[SQL client result modes]  and https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/dev/datastream/execution_mode/[streaming vs. batch execution]
