Now that you have an uberjar containing `MultithreadedKafkaConsumerPerfTest`, you can launch it locally.
This will run until the expected 10,000 records have been consumed. Ensure that the `seq` command that you ran previously to
produce 10,000 records has completed before running this so that we can accurately test consumption throughput.

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/confluent-parallel-consumer-application/kafka/code/tutorial-steps/perftest/run-kafka-consumer-perftest.sh %}</code></pre>
+++++

While the performance test runs, take a few sips of the beverage that you previously poured. It will take a minute or
two to complete, and the final line output will show you the latency for consuming all 10,000 records, e.g.:

+++++
<pre class="snippet"><code class="shell">[main] INFO io.confluent.developer.MultithreadedKafkaConsumer - Total time to consume 10000 records: 40.46 seconds</code></pre>
+++++

Before we build and run a Confluent Parallel Consumer analogue to this `KafkaConsumer` baseline, let's summarize what we've seen so far:

. We populated a topic with default properties and produced 10,000 small records to it
. We maxed out the size of our consumer group by running a `KafkaConsumer` per partition, with each instance explicitly assigned to one partition
. We optimized each `KafkaConsumer` for throughput by setting high values for `max.poll.records` and `fetch.min.bytes`
. We struck a balance between latency accuracy and instrumentation overhead needed to track progress and
   end when expected by using a 0.5 second `poll` timeout. (We want to report consumption latency shortly after consumption finishes,
   but we also want to minimize busy waiting of the `KafkaConsumer` instances that finish first.)
. We scratched our head writing some tricky multi-threaded code. By the way, is any multi-threaded code not tricky?
. The reported performance test latency was *40.46 seconds* in our case (your number is surely different).