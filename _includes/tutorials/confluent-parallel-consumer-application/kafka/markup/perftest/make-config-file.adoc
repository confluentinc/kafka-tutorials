Then create two performance test configuration files. The first is for performance testing a multi-threaded `KafkaConsumer`-based
performance test that we'll use to set a baseline. Create this file at `configuration/perftest-kafka-consumer.properties`:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/confluent-parallel-consumer-application/kafka/code/configuration/perftest-kafka-consumer.properties %}</code></pre>
+++++

Then create this file at `configuration/perftest-parallel-consumer.properties`:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/confluent-parallel-consumer-application/kafka/code/configuration/perftest-parallel-consumer.properties %}</code></pre>
+++++

Let's look at some of the more important properties in these configuration files:

. We specify `fetch.min.bytes` to be 100000 in order to https://docs.confluent.io/cloud/current/client-apps/optimizing/throughput.html#consumer-fetching[optimize for consumer throughput]
. The application-specific property `records.to.consume` is set to `10000` to match the number of records that we produced in the previous step. This will cause the application to terminate upon consuming this many records.
. The application-specific property `record.handler.sleep.ms` is used to simulate a nontrivial amount of work to perform per record. In this case, we sleep for 20ms to simulate a low-but-nontrivial latency operation like a call to a database or REST API.

In the configuration file for the Confluent Parallel Consumer performance test, there are a few Confluent Parallel Consumer-specific properties.

. `parallel.consumer.max.concurrency` is set to `256`, much higher than the number of partitions in our topic
. We use `UNORDERED` ordering, `PERIODIC_CONSUMER_ASYNCHRONOUS` offset commit mode, and a high `parallel.consumer.seconds.between.commits` value of 60 seconds.
  Together, these values optimize for throughput. This keeps our test analogous to the `KafkaConsumer`-based baseline. You may have noticed that,
  because we are aiming to maximize throughput in these performance tests while ignoring the overhead of offsets handling, the baseline doesn't even commit offsets!