The following Scala class will be the entry point of the producer application.
At `src/main/scala/io/confluent/developer/Producer.scala` add:

+++++
<pre class="snippet"><code class="java">{%
    include_raw tutorials/produce-consume-lang/scala/code/src/main/scala/io/confluent/developer/Producer.scala
%}</code></pre>
+++++

Lets's describe the keys pieces of this program.

- Reminder: we use an externalised config and this app loads its config from the _producer_ bloc
of the `application.conf`

A `Producer#produce` function covers most of the record production.

- `Producer#produce` takes a
`https://kafka.apache.org/25/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html[KafkaProducer]`,
a topic name, and an instance of book to send into a Kafka topic.

- `Producer#produce` wraps our book with a `ProducerRecord[K, V]`, that's where attache the topic name to the book.

- `Producer#produce` call the `KafkaProducer#send` method and gets back Java future tight to the broker acknowledgement.

- `Producer#produce` use a
`https://kafka.apache.org/25/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html[CallBack]`
to confirm the future completion and the record write.

ðŸ¤” ðŸ¤” Now what do we need to call our new `Producer#produce` function?

- The `KafkaProducer` has types parameter corresponding to its key and value types. Its constructor takes
serializer / deserializers with the same types.

- `reflectionSerializer4S[T]` is introduced to lighten the tutorial and quickly get a `Serializer[Book]` (See dev part nÂ°3).

- We carefully configure, the serializer with a map containing the schema-registry url.

- The keys will always be null in our example, so we choose an arbitrary type such `Bytes`
from _kafka.common.utils_ package.

- Then we instantiate the `KafkaProducer` by passing a Java Properties from the _producer.client-config_ block of
`application.conf`

That's it! we are ready to produce records.

Note that at the end of the programme we use `KafkaProducer#flush` to check
if the latest messages have been written and `KafkaProducer#close` stop our connection.
