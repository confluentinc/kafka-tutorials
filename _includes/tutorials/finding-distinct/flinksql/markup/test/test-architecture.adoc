Now that you have manually developed and tested your Flink SQL application, how might you create an automated test for
it so that it's easier to maintain and upgrade over time? Imagine how painful it would be to have to manually test every change or
software dependency upgrade of your application, and then imagine having to do this for many applications. The benefits of
automated testing are clear, but how do we get there?

First, what do we want in an automated integration test? For starters:

. *Real running services* that our application depends on
. *Small resource footprint* so that developers can run the test locally
. *Low enough latency* so that development iterations aren't hampered -- not as low latency as is required for a unit test, but test duration should be on the order of seconds
. *Isolation* so that many tests can run concurrently on the same machine when this test gets run on a build automation server, e.g., no hardcoded ports

Luckily, tools are at our disposal to solve these problems. We'll use https://www.testcontainers.org/[Testcontainers] to run
containerized Kafka and Schema Registry servers on dynamic ports, Flink's support for local execution environments so that we don't need to spin up a Flink cluster, and Flink's Table API
in order to execute the Flink SQL statements that comprise our application.
