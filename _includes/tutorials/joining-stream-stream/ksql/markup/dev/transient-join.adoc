Let's cross both streams to come up with a new stream that contains more insightful information such as which orders have been shipped, which warehouse shipped them, and how long did it take to ship each order. The following query does a inner join between the orders stream and the shipments stream, and specifies a window duration of seven days to represent the SLA of one week to ship orders. This will block and continue to return results until it's limit is reached or you tell it to stop.

+++++
<pre class="snippet"><code class="sql">{% include_raw tutorials/joining-stream-stream/ksql/code/tutorial-steps/dev/transient-join.sql %}</code></pre>
+++++

This should yield the following output:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/joining-stream-stream/ksql/code/tutorial-steps/dev/expected-transient.log %}</code></pre>
+++++

The output shown above has some extra information beyond what meets the eye. Since both `orders` and `shipments` streams are using a field to represent the exact time when these events happened, the window created will be based in that instead of considering the timestamp of when the records arrived in Apache Kafka. We call this event time, which is the time determined by data on the event, instead of the ingestion time which is when the record is stored in a partition on the broker.