Secondly, you'll need a Kafka stream and its underlying topic to represent the shipments:

+++++
<pre class="snippet"><code class="sql">{% include_raw tutorials/joining-stream-stream/flinksql/code/tutorial-steps/dev/create-shipments-stream.sql %}</code></pre>
+++++

You might have noticed that we specified `4` partitions for both streams. It's not random that both streams have the same partition count.
For joins to work correctly, the topics need to be _co-partitioned_, which is a fancy way of saying that all topics have the same number of partitions and are keyed the same way. This helps the stream processing infrastructure reason about where the same "kind" of data is without scanning all of the partitions, which would be prohibitively expensive. If your topics are generated by other ksqlDB operations, ksqlDB will automatically co-partition your topics for you. You can learn more about the joining criteria in https://docs.ksqldb.io/en/latest/developer-guide/joins/partition-data/[the full documentation].