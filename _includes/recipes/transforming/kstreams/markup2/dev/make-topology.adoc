Then create the following file at <code>src/main/java/io/confluent/developer/TransformStream.java</code>. Let's take a close look at the <code>buildTopology()</code> method, which uses the Kafka Streams DSL.

The first thing the method does is create an instance of <code>StreamsBuilder</code>, which is the helper object that lets us build our topology. Next we call the <code>stream()</code> method, which creates a <code><a href="https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KStream.html">KStream</a></code> object (called <code>rawMovies</code> in this case) out of an underlying Kafka topic. Note the type of that stream is <code>Long, RawMovie</code>, because the topic contains the raw movie objects we want to transform. RawMovie's <code>title</code> field contains the title and the release year together, which we want to make into separate fields in a new object.

We get that transforming work done with the next line, which is a call to the <code><a href="https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KStream.html#map-org.apache.kafka.streams.kstream.KeyValueMapper-">map()</a></code> method. <code>map()</code> takes each input record and creates a new stream with transformed records in it. Its parameter is a single Java Lambda that takes the input key and value and returns an instance of the <code>KeyValue</code> class with the new record in it. This does two things. First, it rekeys the incoming stream, using the <code>movieId</code> as the key. We don't absolutely need to do that to accomplish the transformation, but it's easy enough to do at the same time, and it sets a useful key on the output stream, which is generally a good idea. Second, it calls the <code>convertRawMovie()</code> method to turn the <code>RawMovie</code> value into a <code>Movie</code>. This is the essence of the transformation. The <code>convertRawMovie()</code> method contains the sort of unpleasant string parsing that is a part of many stream processing pipelines, which we are happily able to encapsulate in a single, easily testable method. Any further stages we might build in the pipeline after this point are blissfully unaware that we ever had a string to parse in the first place.

Moreover, it's worth noting that we're calling <code>map()</code> and not <code>mapValues()</code>:

+++++
<pre class="snippet"><code class="java">{% include_raw recipes/transforming/kstreams/code/src/main/java/io/confluent/developer/TransformStream.java %}</code></pre>
+++++