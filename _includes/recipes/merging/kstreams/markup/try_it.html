<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">1. Get Confluent Platform</h4>

  <p>If you haven't already, get Confluent Platform.</p>
  <pre class="snippet"><code class="shell">{% include shared-content/docker-install.txt %}</code></pre>
</div>

<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">2. Initialize the project</h4>

  <p>To get started, make a new directory anywhere you'd like for this project:</p>
  <pre class="snippet"><code class="shell">mkdir merge-streams && cd merge-streams</code></pre>

  <p>Then create the following Gradle build file, named <code>build.gradle</code> for the project:</p>
  <pre class="snippet"><code class="groovy">{% include_raw recipes/merging/kstreams/code/build.gradle %}</code></pre>

  <p>Next, create a directory for configuration data:</p>
  <pre class="snippet"><code class="shell">mkdir configuration</code></pre>

  <p>Then create a development file at <code>configuration/dev.properties</code>:</p>
  <pre class="snippet"><code class="shell">{% include_raw recipes/merging/kstreams/code/configuration/dev.properties %}</code></pre>
</div>

<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">3. Create a schema for the events</h4>

  <p>Create a directory for the schemas that represent the events in the stream:</p>
  <pre class="snippet"><code class="shell">mkdir -p src/main/avro</code></pre>

  <p>Then create the following Avro schema file at <code>src/main/avro/song_event.avsc</code> for the events representing a song being played:</p>
  <pre class="snippet"><code class="avro">{% include_raw recipes/merging/kstreams/code/src/main/avro/song_event.avsc %}</code></pre>

  <p>Because we will use this Avro schema in our Java code, we'll need to compile it. Run the following:</p>
  <pre class="snippet"><code class="shell">gradle build</code></pre>
</div>

<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">4. Create the Kafka Streams topology</h4>

  <p>Create a directory for the Java files in this project:</p>
  <pre class="snippet"><code class="shell">mkdir -p src/main/java/io/confluent/developer</code></pre>

  <p>Then create the following file at <code>src/main/java/io/confluent/developer/MergeStreams.java</code>. Notice the <code>buildTopology</code> method, which uses the Kafka Streams DSL. A <code>stream</code> is opened up for each input topic. These streams are then connected to the <code>to</code> method, which the name of a Kafka topic to send the events to. This effectively combines all of the events to the output topic.</p>
  <pre class="snippet"><code class="java">{% include_raw recipes/merging/kstreams/code/src/main/java/io/confluent/developer/MergeStreams.java %}</code></pre>
</div>

<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">5. Compile and run the Kafka Streams program</h4>

  <p>In your terminal, run:</p>
  <pre class="snippet"><code class="shell">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/build-uberjar.sh %}</code></pre>

  <p>Now that an uberjar for the Kafka Streams application has been built, you can launch it locally. When you run the following, the prompt won't return, because the application will run until you exit it:</p>
  <pre class="snippet"><code class="shell">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/run-dev-app.sh %}</code></pre>
</div>

<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">6. Produce events to the input topics</h4>

  <p>To produce the input events to their respective topics, you'll want two terminals running. To send the rock songs to their topic, open up a terminal and run the following:</p>
  <pre class="snippet"><code class="shell">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/console-producer-rock.sh %}</code></pre>

  <p>When the console producer starts, it will log some messages and hang, waiting for your input. Type in one line at a time and press enter to send it. Each line represents an event. To send all of the events below, paste the following into the prompt and press enter:</p>
  <pre class="snippet"><code class="json">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/rock-input-events.json %}</code></pre>

  <p>To produce the classical songs, open up another terminal and run:</p>
  <pre class="snippet"><code class="shell">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/console-producer-classical.sh %}</code></pre>

  <p>Then paste in the following events:</p>
  <pre class="snippet"><code class="json">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/classical-input-events.json %}</code></pre>
</div>

<div class="recipe-try-it-step">
  <h4 class="subtitle is-4">7. Consume events from the output topic</h4>
  
  <p>Leaving your original terminals running, open another to consume the events that have been merged</p>
  <pre class="snippet"><code class="shell">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/console-consumer.sh %}</code></pre>

  <p>After the consumer starts, you should see the following messages. The order might vary depending on the timing of which the input events are sent to each topic and processed by the app. Kafka Streams will coalesce the respective input topics together in an indeterminate manner. To continue studying the example, send more events through the input terminal prompt. Otherwise, you can <code>Control-C</code> to exit the process.</p>
  <pre class="snippet"><code class="json">{% include_raw recipes/merging/kstreams/harness/recipe-steps/dev/outputs/actual-output-events.json %}</code></pre>
</div>
